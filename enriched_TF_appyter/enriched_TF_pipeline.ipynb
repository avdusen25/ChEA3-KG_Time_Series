{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c671de6",
   "metadata": {},
   "source": [
    "# Visualizing the Enriched Transcription Factors from Time Series RNA-seq Experiments\n",
    "### The Appyter below generates a regulatory subnetwork and a UMAP visualization of the enriched TFs at different time points from time series RNA-seq data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695dcf3",
   "metadata": {},
   "source": [
    "## Loading the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa55b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "from appyter import magic\n",
    "magic.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import urllib.parse\n",
    "from urllib.parse import quote\n",
    "import requests\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from IPython.display import Image as IPyImage, Javascript, display, FileLink\n",
    "import os\n",
    "import time\n",
    "\n",
    "# time series TF subnetwork visualization\n",
    "import ipycytoscape as ipc\n",
    "from ipycytoscape import CytoscapeWidget, Node, Edge\n",
    "import py4cytoscape as p4c\n",
    "import networkx as nx\n",
    "from dash import Dash, html\n",
    "\n",
    "# enriched TF UMAP visualization\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "from collections import OrderedDict\n",
    "from bokeh.io import output_notebook, export_png, export_svg\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import HoverTool, ColumnDataSource\n",
    "from bokeh.palettes import Category20\n",
    "import glasbey\n",
    "output_notebook()\n",
    "\n",
    "from maayanlab_bioinformatics.dge import deseq2_differential_expression\n",
    "from maayanlab_bioinformatics.dge import characteristic_direction\n",
    "from maayanlab_bioinformatics.dge import up_down_from_characteristic_direction\n",
    "from maayanlab_bioinformatics.dge import limma_voom_differential_expression\n",
    "from maayanlab_bioinformatics.dge import up_down_from_limma_voom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bfe09b",
   "metadata": {},
   "source": [
    "## 1. Finding DEGs given a raw gene counts matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ceb21b",
   "metadata": {},
   "source": [
    "### Upload fields for raw gene counts matrix and experiment metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70226435",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide_code\n",
    "\n",
    "{% do SectionField(\n",
    "    name= 'section1',\n",
    "    title= '1. Upload raw gene counts matrix.'\n",
    ") %}\n",
    "\n",
    "{% do SectionField(\n",
    "    name= 'section2',\n",
    "    title= '2. Upload experiment metadata.'\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa272ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_eval\n",
    "\n",
    "{% set dataset1 = FileField(\n",
    "    name= 'dataset1',\n",
    "    label= 'Raw gene counts matrix',\n",
    "    default= '',\n",
    "    examples= {'Raw gene counts from TRAIL-treated TNBC cell line': 'https://drive.google.com/uc?export=download&id=1WFtUIXO2b3rbiStJ7Hf8Bx7NrfheEM9L'},\n",
    "    section= 'section1'\n",
    ") %}\n",
    "\n",
    "ds1 = {{dataset1}}\n",
    "ds1\n",
    "\n",
    "{% do DescriptionField(\n",
    "    name= 'description',\n",
    "    text= 'See example for how to format experiment metadata file. Ensure that the columns are labeled exactly as \"sample_name\" and \"time_pt_annotation\".',\n",
    "    section= 'section2'\n",
    ") %}\n",
    "\n",
    "{% set dataset2 = FileField(\n",
    "    name= 'dataset2',\n",
    "    label= 'Experiment metadata',\n",
    "    default= '',\n",
    "    examples= {'Samples taken from TRAIL-treated TNBC cell line': 'https://drive.google.com/uc?export=download&id=1iyGR_LC2MPHQ0LyobzMFULbGIYFSYH2Y'},\n",
    "    section= 'section2'\n",
    ") %}\n",
    "\n",
    "ds2 = {{dataset2}}\n",
    "ds2\n",
    "\n",
    "compute_degs = False\n",
    "if ds1 != '' and ds2 != '':\n",
    "    compute_degs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56cbfd2",
   "metadata": {},
   "source": [
    "### Method 1: PyDESeq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d6b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_degs:\n",
    "    raw_counts = pd.read_csv(ds1)\n",
    "    sample_metadata = pd.read_csv(ds2)\n",
    "\n",
    "    time_pt_list = []\n",
    "    for time_pt in sample_metadata[\"time_pt_annotation\"].tolist():\n",
    "        if time_pt not in time_pt_list:\n",
    "            time_pt_list.append(time_pt)\n",
    "\n",
    "    time_pt_dict = {}\n",
    "    for i, time_pt in enumerate(time_pt_list):\n",
    "        samples_at_time_pt = sample_metadata.loc[sample_metadata[\"time_pt_annotation\"] == time_pt, \"sample_name\"].tolist()\n",
    "        subset_counts = raw_counts[[\"gene_id\"] + samples_at_time_pt]\n",
    "        rev_subset_counts = subset_counts.set_index(\"gene_id\")\n",
    "        time_pt_dict[i] = (time_pt, rev_subset_counts)\n",
    "    # print(time_pt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219cdcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### [DESeq2] finding the DEGs from adjacent time pt comparisons\n",
    "if compute_degs:\n",
    "    adj_time_pt_comparisons = []\n",
    "    adj_time_pt_degs = []\n",
    "    for i in range(len(time_pt_list) - 1):\n",
    "        controls, cases = time_pt_dict[i][1], time_pt_dict[i+1][1]\n",
    "        results_df = deseq2_differential_expression(controls, cases)\n",
    "\n",
    "        p_vals = [0.05, 0.01, 0.001, 0.0001, 0.00001]\n",
    "        significant_genes = results_df[results_df[\"padj\"] < p_vals[0]]\n",
    "        up_count = (significant_genes[\"log2FoldChange\"] > 0).sum()\n",
    "        down_count = (significant_genes[\"log2FoldChange\"] < 0).sum()\n",
    "\n",
    "        idx = 1\n",
    "        while (up_count + down_count) > 2000:\n",
    "            significant_genes = results_df[results_df[\"padj\"] < p_vals[idx]]\n",
    "            up_count = (significant_genes[\"log2FoldChange\"] > 0).sum()\n",
    "            down_count = (significant_genes[\"log2FoldChange\"] < 0).sum()\n",
    "            idx += 1\n",
    "        print(\"total DEGs:\", (up_count + down_count), \"up:\", up_count, \"down:\", down_count, \"padj:\", p_vals[idx-1])\n",
    "        print(significant_genes.head())\n",
    "\n",
    "        ctrl_time_pt, case_time_pt = time_pt_dict[i][0], time_pt_dict[i+1][0]\n",
    "        adj_time_pt_comparisons.append(f\"{case_time_pt} v {ctrl_time_pt}\")\n",
    "\n",
    "        file = f\"deseq2_{case_time_pt}_v_{ctrl_time_pt}.csv\"\n",
    "        significant_genes.to_csv(file)\n",
    "        adj_time_pt_degs.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5be5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### [DESeq2] finding the DEGs from time pt 0 comparisons\n",
    "if compute_degs:\n",
    "    time_pt_0_comparisons = []\n",
    "    time_pt_0_degs = []\n",
    "    for i in range(1, len(time_pt_list)):\n",
    "        controls, cases = time_pt_dict[0][1], time_pt_dict[i][1]\n",
    "        results_df = deseq2_differential_expression(controls, cases)\n",
    "\n",
    "        p_vals = [0.05, 0.01, 0.001, 0.0001, 0.00001]\n",
    "        significant_genes = results_df[results_df[\"padj\"] < p_vals[0]]\n",
    "        up_count = (significant_genes[\"log2FoldChange\"] > 0).sum()\n",
    "        down_count = (significant_genes[\"log2FoldChange\"] < 0).sum()\n",
    "\n",
    "        idx = 1\n",
    "        while (up_count + down_count) > 2000:\n",
    "            significant_genes = results_df[results_df[\"padj\"] < p_vals[idx]]\n",
    "            up_count = (significant_genes[\"log2FoldChange\"] > 0).sum()\n",
    "            down_count = (significant_genes[\"log2FoldChange\"] < 0).sum()\n",
    "            idx += 1\n",
    "        print(\"total DEGs:\", (up_count + down_count), \"up:\", up_count, \"down:\", down_count, \"padj:\", p_vals[idx-1])\n",
    "        print(significant_genes.head())\n",
    "\n",
    "        ctrl_time_pt, case_time_pt = time_pt_dict[0][0], time_pt_dict[i][0]\n",
    "        time_pt_0_comparisons.append(f\"{case_time_pt} v {ctrl_time_pt}\")\n",
    "\n",
    "        file = f\"deseq2_{case_time_pt}_v_{ctrl_time_pt}.csv\"\n",
    "        significant_genes.to_csv(file)\n",
    "        time_pt_0_degs.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903a7430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_gene_list(input_csv, filename=None):\n",
    "    \"\"\"\n",
    "    Outputs list of upregulated DEGs from DESeq2 results CSV.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "    row_filter = df[\"log2FoldChange\"] > 0\n",
    "    filtered = df.loc[row_filter, df.columns[0]]\n",
    "    gene_ids = list(filtered)\n",
    "\n",
    "    up_list = []\n",
    "    for gene in gene_ids:\n",
    "        if \"_\" in gene:\n",
    "            up_list.append(gene.split(\"_\", 1)[1])\n",
    "        else:\n",
    "            up_list.append(gene)\n",
    "\n",
    "    print(len(up_list))\n",
    "    return up_list\n",
    "\n",
    "\n",
    "def down_gene_list(input_csv, filename=None):\n",
    "    \"\"\"\n",
    "    Outputs list of downregulated DEGs from DESeq2 results CSV.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "    row_filter = df[\"log2FoldChange\"] < 0\n",
    "    filtered = df.loc[row_filter, df.columns[0]]\n",
    "    gene_ids = list(filtered)\n",
    "\n",
    "    down_list = []\n",
    "    for gene in gene_ids:\n",
    "        if \"_\" in gene:\n",
    "            down_list.append(gene.split(\"_\", 1)[1])\n",
    "        else:\n",
    "            down_list.append(gene)\n",
    "\n",
    "    print(len(down_list))\n",
    "    return down_list\n",
    "\n",
    "\n",
    "def csv_to_gmt(input_csv_list, comparisons, filename):\n",
    "    gmt_dict = {}\n",
    "    for i, file in enumerate(input_csv_list):\n",
    "        up_genes = up_gene_list(file)\n",
    "        print(len(up_genes))\n",
    "        down_genes = down_gene_list(file)\n",
    "        print(len(down_genes))\n",
    "        gmt_dict[f\"{comparisons[i]} up genes\"] = up_genes\n",
    "        gmt_dict[f\"{comparisons[i]} down genes\"] = down_genes\n",
    "\n",
    "    with open(filename, \"w\") as file:\n",
    "        for s,t in gmt_dict.items():\n",
    "            file.write(str(s) + \"\\t\\t\" + \"\\t\".join(t) + \"\\n\")\n",
    "    print(\"FINISHED CONVERTING TO GMT\")\n",
    "    return filename\n",
    "\n",
    "if compute_degs:\n",
    "    deseq2_degs_gmt_1 = csv_to_gmt(adj_time_pt_degs, adj_time_pt_comparisons, \"appyter_deseq2_adj_time_pt_degs.gmt\")\n",
    "    deseq2_degs_gmt_2 = csv_to_gmt(time_pt_0_degs, time_pt_0_comparisons, \"appyter_deseq2_compare_w_time_pt_0_degs.gmt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b27a30",
   "metadata": {},
   "source": [
    "### Method 2: Characteristic Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8468437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### [CD] finding the DEGs from adjacent time pt comparisons\n",
    "def run_chea_kg(gene_list, num_tfs):\n",
    "    \"\"\"\n",
    "    Outputs JSON of TF subnetwork best corresponding to input gene list.\n",
    "    \"\"\"\n",
    "    CHEA_KG = 'https://chea-kg.maayanlab.cloud/api/enrichment'\n",
    "\n",
    "    description = \"insert description here\"\n",
    "    payload = {\n",
    "        'list': (None, \"\\n\".join(gene_list)),\n",
    "        'description': (None, description)\n",
    "    }\n",
    "    response=requests.post(f\"{CHEA_KG}/addList\", files=payload)\n",
    "    time.sleep(0.2)\n",
    "    data = json.loads(response.text)\n",
    "\n",
    "    q = {\n",
    "        'min_lib': 3, # minimum number of libraries that a TF must be ranked in\n",
    "        'libraries': [\n",
    "            {'library': \"Integrated--meanRank\", 'term_limit': num_tfs} # edit term_limit to change number of top-ranked TFs\n",
    "        ],\n",
    "        'limit':50, # controls number of edges returned - may cause issues with visualization if too large\n",
    "        'userListId': data['userListId']\n",
    "    }\n",
    "    query_json=json.dumps(q)\n",
    "    res = requests.post(CHEA_KG, data=query_json)\n",
    "    if res.ok:\n",
    "        data = json.loads(res.text)\n",
    "        return data\n",
    "    else:\n",
    "        data = None\n",
    "        return res.text\n",
    "\n",
    "\n",
    "def top_tfs(gene_list, num_tfs=5):\n",
    "    \"\"\"\n",
    "    Returns a list of the top N most enriched TFs corresponding to an input gene list.\n",
    "    \"\"\"\n",
    "    enriched_tfs = run_chea_kg(gene_list, num_tfs)\n",
    "    tfs_list = []\n",
    "    for node in enriched_tfs[\"nodes\"]:\n",
    "        tfs_list.append(node[\"data\"][\"label\"])\n",
    "    return tfs_list\n",
    "\n",
    "if compute_degs:\n",
    "    cd_adj_time_pt_comparisons = []\n",
    "    cd_tf_time_dict_1 = {}\n",
    "    for i in range(len(time_pt_list) - 1):\n",
    "        ctrl_time_pt, case_time_pt = time_pt_dict[i][0], time_pt_dict[i+1][0]\n",
    "        cd_adj_time_pt_comparisons.append(f\"{case_time_pt} v {ctrl_time_pt}\")\n",
    "\n",
    "        controls, cases = time_pt_dict[i][1], time_pt_dict[i+1][1]\n",
    "        results_df = characteristic_direction(controls, cases)\n",
    "        # print(results_df.head())\n",
    "\n",
    "        up_genes = up_down_from_characteristic_direction(results_df).up\n",
    "        up_list = []\n",
    "        for gene in up_genes:\n",
    "            if \"_\" in gene:\n",
    "                up_list.append(gene.split(\"_\", 1)[1])\n",
    "            else:\n",
    "                up_list.append(gene)\n",
    "\n",
    "        down_genes = up_down_from_characteristic_direction(results_df).down\n",
    "        down_list = []\n",
    "        for gene in down_genes:\n",
    "            if \"_\" in gene:\n",
    "                down_list.append(gene.split(\"_\", 1)[1])\n",
    "            else:\n",
    "                down_list.append(gene)\n",
    "\n",
    "        # print(up_list)\n",
    "        # print(down_list)\n",
    "        print(len(up_list), len(down_list))\n",
    "\n",
    "        cd_tf_time_dict_1[i] = (top_tfs(up_list), top_tfs(down_list))\n",
    "    print(cd_tf_time_dict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86251ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### [CD] finding the DEGs from time pt 0 comparisons\n",
    "if compute_degs:\n",
    "    cd_time_pt_0_comparisons = []\n",
    "    cd_tf_time_dict_2 = {}\n",
    "    for i in range(1, len(time_pt_list)):\n",
    "        ctrl_time_pt, case_time_pt = time_pt_dict[0][0], time_pt_dict[i][0]\n",
    "        cd_time_pt_0_comparisons.append(f\"{case_time_pt} v {ctrl_time_pt}\")\n",
    "\n",
    "        controls, cases = time_pt_dict[0][1], time_pt_dict[i][1]\n",
    "        results_df = characteristic_direction(controls, cases)\n",
    "\n",
    "        up_genes = up_down_from_characteristic_direction(results_df).up\n",
    "        up_list = []\n",
    "        for gene in up_genes:\n",
    "            if \"_\" in gene:\n",
    "                up_list.append(gene.split(\"_\", 1)[1])\n",
    "            else:\n",
    "                up_list.append(gene)\n",
    "\n",
    "        down_genes = up_down_from_characteristic_direction(results_df).down\n",
    "        down_list = []\n",
    "        for gene in down_genes:\n",
    "            if \"_\" in gene:\n",
    "                down_list.append(gene.split(\"_\", 1)[1])\n",
    "            else:\n",
    "                down_list.append(gene)\n",
    "\n",
    "        # print(up_list)\n",
    "        # print(down_list)\n",
    "        print(len(up_list), len(down_list))\n",
    "\n",
    "        cd_tf_time_dict_2[i-1] = (top_tfs(up_list), top_tfs(down_list))\n",
    "    print(cd_tf_time_dict_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5424dc0",
   "metadata": {},
   "source": [
    "## 2. Defining functions that output the enriched TFs given an input gene set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0175641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chea_kg(gene_list, num_tfs):\n",
    "    \"\"\"\n",
    "    Outputs JSON of TF subnetwork best corresponding to input gene list.\n",
    "    \"\"\"\n",
    "    CHEA_KG = 'https://chea-kg.maayanlab.cloud/api/enrichment'\n",
    "\n",
    "    description = \"insert description here\"\n",
    "    payload = {\n",
    "        'list': (None, \"\\n\".join(gene_list)),\n",
    "        'description': (None, description)\n",
    "    }\n",
    "    response=requests.post(f\"{CHEA_KG}/addList\", files=payload)\n",
    "    time.sleep(0.2)\n",
    "    data = json.loads(response.text)\n",
    "\n",
    "    q = {\n",
    "        'min_lib': 3, # minimum number of libraries that a TF must be ranked in\n",
    "        'libraries': [\n",
    "            {'library': \"Integrated--meanRank\", 'term_limit': num_tfs} # edit term_limit to change number of top-ranked TFs\n",
    "        ],\n",
    "        'limit':50, # controls number of edges returned - may cause issues with visualization if too large\n",
    "        'userListId': data['userListId']\n",
    "    }\n",
    "    query_json=json.dumps(q)\n",
    "\n",
    "    res = requests.post(CHEA_KG, data=query_json)\n",
    "    if res.ok:\n",
    "        data = json.loads(res.text)\n",
    "        return data\n",
    "    else:\n",
    "        data = None\n",
    "        return res.text\n",
    "\n",
    "\n",
    "def top_tfs(gene_list, num_tfs=5):\n",
    "    \"\"\"\n",
    "    Returns a list of the top N most enriched TFs corresponding to an input gene list.\n",
    "    \"\"\"\n",
    "    enriched_tfs = run_chea_kg(gene_list, num_tfs)\n",
    "    tfs_list = []\n",
    "    for node in enriched_tfs[\"nodes\"]:\n",
    "        tfs_list.append(node[\"data\"][\"label\"])\n",
    "    return tfs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa8d98",
   "metadata": {},
   "source": [
    "## 3. Defining subnetwork visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ddb535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_chea_kg_data(start_tf, end_tf):\n",
    "    \"\"\"\n",
    "    Outputs JSON data for shortest path connecting two TFs.\n",
    "    \"\"\"\n",
    "    base_url = \"https://chea-kg.maayanlab.cloud/api/knowledge_graph\"\n",
    "\n",
    "    query_filter = {\n",
    "        \"start\": \"Transcription Factor\",\n",
    "        \"start_field\": \"label\",\n",
    "        \"start_term\": start_tf,\n",
    "        \"end\": \"Transcription Factor\",\n",
    "        \"end_field\": \"label\",\n",
    "        \"end_term\": end_tf\n",
    "    }\n",
    "\n",
    "    encoded_filter = urllib.parse.quote(str(query_filter).replace(\"'\", '\"'))\n",
    "    full_url = f\"{base_url}?filter={encoded_filter}\"\n",
    "\n",
    "    response = requests.get(full_url)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_tf_node_info(tf_label):\n",
    "    \"\"\"\n",
    "    Gets node information associated with single TF.\n",
    "    \"\"\"\n",
    "    base_url = \"https://chea-kg.maayanlab.cloud/api/knowledge_graph\"\n",
    "\n",
    "    query_filter = {\n",
    "        \"start\": \"Transcription Factor\",\n",
    "        \"start_field\": \"label\",\n",
    "        \"start_term\": tf_label\n",
    "    }\n",
    "    encoded_filter = urllib.parse.quote(str(query_filter).replace(\"'\", '\"'))\n",
    "    full_url = f\"{base_url}?filter={encoded_filter}\"\n",
    "\n",
    "    response = requests.get(full_url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    for node in data[\"nodes\"]:\n",
    "        if node[\"data\"][\"label\"] == tf_label:\n",
    "            return node\n",
    "    raise ValueError(f\"Node for TF '{tf_label}' not found in response.\")\n",
    "\n",
    "\n",
    "def get_tf_edge_info(tf_label):\n",
    "    \"\"\"\n",
    "    Returns edge info if TF is autoregulatory.\n",
    "    \"\"\"\n",
    "    base_url = \"https://chea-kg.maayanlab.cloud/api/knowledge_graph\"\n",
    "\n",
    "    query_filter = {\n",
    "        \"start\": \"Transcription Factor\",\n",
    "        \"start_field\": \"label\",\n",
    "        \"start_term\": tf_label\n",
    "    }\n",
    "    encoded_filter = urllib.parse.quote(str(query_filter).replace(\"'\", '\"'))\n",
    "    full_url = f\"{base_url}?filter={encoded_filter}\"\n",
    "\n",
    "    response = requests.get(full_url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    for edge in data[\"edges\"]:\n",
    "        if edge[\"data\"][\"source_label\"] == tf_label and edge[\"data\"][\"target_label\"] == tf_label:\n",
    "            return edge\n",
    "    raise ValueError(f\"Self-edge for TF '{tf_label}' not found in response.\")\n",
    "\n",
    "\n",
    "def create_tf_time_series_graph(tf_time_dict, num_comparisons, filename):\n",
    "    \"\"\"\n",
    "    Creates network of TFs given differentially expressed genes at each time point.\n",
    "    \"\"\"\n",
    "    subnetwork = {\"nodes\": [], \"edges\": []}\n",
    "    for time in tf_time_dict.keys():\n",
    "        up_tfs = tf_time_dict[time][0]\n",
    "        down_tfs = tf_time_dict[time][1]\n",
    "\n",
    "        for tf in up_tfs:\n",
    "            node_info = get_tf_node_info(tf)\n",
    "            node_info[\"data\"][\"color\"] = \"#80eaff\"\n",
    "            node_info[\"data\"][\"id\"] = f\"{node_info['data']['label']}_up_{time}\"\n",
    "            subnetwork[\"nodes\"].append(node_info)\n",
    "\n",
    "        for tf in down_tfs:\n",
    "            node_info = get_tf_node_info(tf)\n",
    "            node_info[\"data\"][\"color\"] = \"#ff8a80\"\n",
    "            node_info[\"data\"][\"id\"] = f\"{node_info['data']['label']}_down_{time}\"\n",
    "            subnetwork[\"nodes\"].append(node_info)\n",
    "\n",
    "    for i in range(num_comparisons-1):\n",
    "        for j, source_tf_list in enumerate(tf_time_dict[i]):\n",
    "            for k, target_tf_list in enumerate(tf_time_dict[i+1]):\n",
    "                for source_tf in source_tf_list:\n",
    "                    for target_tf in target_tf_list:\n",
    "                        if source_tf != target_tf:\n",
    "                            data = fetch_chea_kg_data(source_tf, target_tf)\n",
    "                            if len(data[\"nodes\"]) == 2 and len(data[\"edges\"]) == 1:\n",
    "                                if data[\"edges\"][0][\"data\"][\"source_label\"] == source_tf and \\\n",
    "                                    data[\"edges\"][0][\"data\"][\"target_label\"] == target_tf:\n",
    "                                    if j == 0 and k == 0:\n",
    "                                        data[\"edges\"][0][\"data\"][\"source\"] = f\"{source_tf}_up_{i}\"\n",
    "                                        data[\"edges\"][0][\"data\"][\"target\"] = f\"{target_tf}_up_{i+1}\"\n",
    "                                    elif j == 0 and k == 1:\n",
    "                                        data[\"edges\"][0][\"data\"][\"source\"] = f\"{source_tf}_up_{i}\"\n",
    "                                        data[\"edges\"][0][\"data\"][\"target\"] = f\"{target_tf}_down_{i+1}\"\n",
    "                                    elif j == 1 and k == 0:\n",
    "                                        data[\"edges\"][0][\"data\"][\"source\"] = f\"{source_tf}_down_{i}\"\n",
    "                                        data[\"edges\"][0][\"data\"][\"target\"] = f\"{target_tf}_up_{i+1}\"\n",
    "                                    elif j == 1 and k == 1:\n",
    "                                        data[\"edges\"][0][\"data\"][\"source\"] = f\"{source_tf}_down_{i}\"\n",
    "                                        data[\"edges\"][0][\"data\"][\"target\"] = f\"{target_tf}_down_{i+1}\"\n",
    "                                    subnetwork[\"edges\"].append(data[\"edges\"][0])\n",
    "                                    print(\"edge added, case 1\")\n",
    "                        else:\n",
    "                            if len(source_tf_list) != 0:\n",
    "                                try:\n",
    "                                    edge = get_tf_edge_info(source_tf)\n",
    "                                    if j == 0 and k == 0:\n",
    "                                        edge[\"data\"][\"source\"] = f\"{source_tf}_up_{i}\"\n",
    "                                        edge[\"data\"][\"target\"] = f\"{target_tf}_up_{i+1}\"\n",
    "                                    elif j == 0 and k == 1:\n",
    "                                        edge[\"data\"][\"source\"] = f\"{source_tf}_up_{i}\"\n",
    "                                        edge[\"data\"][\"target\"] = f\"{target_tf}_down_{i+1}\"\n",
    "                                    elif j == 1 and k == 0:\n",
    "                                        edge[\"data\"][\"source\"] = f\"{source_tf}_down_{i}\"\n",
    "                                        edge[\"data\"][\"target\"] = f\"{target_tf}_up_{i+1}\"\n",
    "                                    elif j == 1 and k == 1:\n",
    "                                        edge[\"data\"][\"source\"] = f\"{source_tf}_down_{i}\"\n",
    "                                        edge[\"data\"][\"target\"] = f\"{target_tf}_down_{i+1}\"\n",
    "                                    subnetwork[\"edges\"].append(edge)\n",
    "                                    print(\"edge added, case 2\")\n",
    "                                except ValueError:\n",
    "                                    continue\n",
    "    output_path = f\"{filename}.json\"\n",
    "    with open(output_path, \"w\") as outfile:\n",
    "        json.dump(subnetwork, outfile, indent=4)\n",
    "    print(\"FINISHED\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def gmt_to_tf_time_dict(gmt_file):\n",
    "    \"\"\"\n",
    "    Converts GMT file containing DEGs to tf_time_dict.\n",
    "    \"\"\"\n",
    "    with open(gmt_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    temp_dict = {}\n",
    "    for line in lines:\n",
    "        tokens = line.split(\"\\t\\t\")\n",
    "        term = tokens[0]\n",
    "        genes = [x.split(',')[0].strip() for x in tokens[1].split('\\t')]\n",
    "        temp_dict[term] = top_tfs(genes)\n",
    "        print(\"enriched TFs found\")\n",
    "\n",
    "    comparisons = list(temp_dict.keys())\n",
    "    new_comparisons = []\n",
    "    for item in comparisons:\n",
    "        comp = item.rsplit(' ', 2)[0]\n",
    "        if comp not in new_comparisons:\n",
    "            new_comparisons.append(comp)\n",
    "    print(\"Time point comparisons:\", new_comparisons)\n",
    "\n",
    "    j = 0\n",
    "    tf_time_dict = {}\n",
    "    for i in range(len(comparisons) // 2):\n",
    "        tf_time_dict[i] = (temp_dict[comparisons[j]], temp_dict[comparisons[j+1]])\n",
    "        j += 2\n",
    "    print(tf_time_dict)\n",
    "    return tf_time_dict, new_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide_code\n",
    "\n",
    "{% do SectionField(\n",
    "    name= 'data',\n",
    "    title= '3. Upload differentially expressed genes (only if uploading a GMT file rather than a raw gene counts matrix).'\n",
    ")%}\n",
    "\n",
    "{% do SectionField(\n",
    "    name= 'section4',\n",
    "    title= '4. Provide a short description of your study (optional).'\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_eval\n",
    "\n",
    "{% do DescriptionField(\n",
    "    name= 'description_2',\n",
    "    text= 'See example files for how to format input GMT file. Each row should consist of either the \"up\" or \"down\" differentially expressed genes at each time point comparison.',\n",
    "    section= 'data'\n",
    ") %}\n",
    "\n",
    "{% set dataset3 = FileField(\n",
    "    name= 'dataset3',\n",
    "    label= 'GMT file containing DEGs from ADJACENT TIME POINT COMPARISONS',\n",
    "    default= '',\n",
    "    examples= {'First set of DEGs from TRAIL-treated TNBC cell line': 'https://drive.google.com/uc?export=download&id=1tFNWDYPX553R1g9RDIUfMkoY2j3lXEw4'},\n",
    "    section= 'data'\n",
    ") %}\n",
    "\n",
    "ds3 = {{dataset3}}\n",
    "ds3\n",
    "\n",
    "{% set dataset4 = FileField(\n",
    "    name= 'dataset4',\n",
    "    label= 'GMT file containing DEGs from COMPARISONS WITH TIME POINT 0',\n",
    "    default= '',\n",
    "    examples= {'Second set of DEGS from TRAIL-treated TNBC cell line': 'https://drive.google.com/uc?export=download&id=1NSFdnybH35EJhXY6_iHZf09PS-EeFvQh'},\n",
    "    section= 'data'\n",
    ") %}\n",
    "\n",
    "ds4 = {{dataset4}}\n",
    "ds4\n",
    "\n",
    "{% set user_description = TextField(\n",
    "        name= 'user_description',\n",
    "        label= 'Description',\n",
    "        default= '',\n",
    "        section = 'section4',\n",
    ") %}\n",
    "\n",
    "umap_desc = {{user_description}}\n",
    "umap_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde58a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_degs:\n",
    "    deseq2_tf_time_dict_1, deseq2_adj_time_pt_comparisons = gmt_to_tf_time_dict(deseq2_degs_gmt_1)\n",
    "    deseq2_subnetwork_data_1 = create_tf_time_series_graph(deseq2_tf_time_dict_1, len(deseq2_adj_time_pt_comparisons), \"appyter_deseq2_adj_time_pts_top_5_tfs\")\n",
    "\n",
    "    deseq2_tf_time_dict_2, deseq2_time_pt_0_comparisons = gmt_to_tf_time_dict(deseq2_degs_gmt_2)\n",
    "    deseq2_subnetwork_data_2 = create_tf_time_series_graph(deseq2_tf_time_dict_2, len(deseq2_time_pt_0_comparisons), \"appyter_deseq2_compare_w_time_pt_0_top_5_tfs\")\n",
    "\n",
    "    cd_subnetwork_data_1 = create_tf_time_series_graph(cd_tf_time_dict_1, len(cd_adj_time_pt_comparisons), \"appyter_cd_adj_time_pts_top_5_tfs\")\n",
    "    cd_subnetwork_data_2 = create_tf_time_series_graph(cd_tf_time_dict_2, len(cd_time_pt_0_comparisons), \"appyter_cd_compare_w_time_pt_0_top_5_tfs\")\n",
    "\n",
    "else:\n",
    "    tf_time_dict_1, comparisons_1 = gmt_to_tf_time_dict(ds3)\n",
    "    subnetwork_data_1 = create_tf_time_series_graph(tf_time_dict_1, len(comparisons_1), \"appyter_deseq2_adj_time_pts_top_5_tfs\")\n",
    "\n",
    "    tf_time_dict_2, comparisons_2 = gmt_to_tf_time_dict(ds4)\n",
    "    subnetwork_data_2 = create_tf_time_series_graph(tf_time_dict_2, len(comparisons_2), \"appyter_deseq2_compare_w_time_pt_0_top_5_tfs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3140530",
   "metadata": {},
   "source": [
    "## 4. Visualizing the enriched TFs within a time series regulatory subnetwork\n",
    "### Blue and red nodes correspond to TFs enriched for upregulated and downregulated gene sets, respectively, at the given time point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_cytoscape_json(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    display(FileLink(filename))\n",
    "\n",
    "\n",
    "def visualize_network_2(data, filename):\n",
    "    row_col_dict = {}\n",
    "    for node in data[\"nodes\"]:\n",
    "        if \"position\" in node:\n",
    "            continue\n",
    "        node_id = node[\"data\"][\"id\"]\n",
    "        row_index = int(node_id.split(\"_\")[-1])\n",
    "        col_index = row_col_dict.get(row_index, 1)\n",
    "        row_col_dict[row_index] = col_index + 1\n",
    "        node[\"position\"] = {\"x\": col_index * 150, \"y\": row_index * 150}\n",
    "\n",
    "    cyto_widget = CytoscapeWidget()\n",
    "    cyto_widget.graph.add_graph_from_json(data)\n",
    "    cyto_widget.set_layout(name='preset')\n",
    "\n",
    "    cyto_widget.set_style([{\n",
    "        'selector': 'node',\n",
    "        'style': {\n",
    "            'label': 'data(label)',\n",
    "            'background-color': 'data(color)',\n",
    "            'border-width': 'data(borderWidth)',\n",
    "            'border-color': 'data(borderColor)',\n",
    "            'width': 40,\n",
    "            'height': 40\n",
    "        }\n",
    "    }, {\n",
    "        'selector': '.row-label',\n",
    "        'style': {\n",
    "            'label': 'data(label)',\n",
    "            'background-color': '#ffffff',\n",
    "            'color': '#000000',\n",
    "            'font-size': '20px',\n",
    "            'width': 5,\n",
    "            'height': 5,\n",
    "            'text-valign': 'center',\n",
    "            'text-halign': 'center'\n",
    "        }\n",
    "    }, {\n",
    "        'selector': 'edge',\n",
    "        'style': {\n",
    "            'width': 3,\n",
    "            'line-color': 'data(lineColor)',\n",
    "            'target-arrow-color': 'data(lineColor)',\n",
    "            'target-arrow-shape': 'data(directed)',\n",
    "            'curve-style': 'bezier',\n",
    "            'arrow-scale': 1.5\n",
    "        }\n",
    "    }])\n",
    "\n",
    "    display(cyto_widget)\n",
    "    json_filename = f\"{filename}.json\"\n",
    "    export_cytoscape_json(data, json_filename)\n",
    "\n",
    "\n",
    "def run_visualization(input_json, comparisons, filename):\n",
    "    if isinstance(input_json, dict):\n",
    "        data = input_json\n",
    "    else:\n",
    "        with open(input_json, \"r\") as input_file:\n",
    "            data = json.load(input_file)\n",
    "\n",
    "    nodes = data[\"nodes\"]\n",
    "    for i, comparison in enumerate(comparisons):\n",
    "        label_node = {\n",
    "            'data': {\n",
    "                'id': f'row_label_{i}',\n",
    "                'label': comparison,\n",
    "                'color': '#ffffff',\n",
    "                'borderColor': '#ffffff',\n",
    "                'borderWidth': 0\n",
    "            },\n",
    "            'classes': 'row-label',\n",
    "            'position': {\"x\": 0, \"y\": i * 150}\n",
    "        }\n",
    "        nodes.append(label_node)\n",
    "\n",
    "    visualize_network_2(data, filename)\n",
    "    return \"VISUALIZATION HAS RUN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc8b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if compute_degs:\n",
    "#     print(\"deseq2_adj_time_pt_visualization:\")\n",
    "#     run_visualization(deseq2_subnetwork_data_1, deseq2_adj_time_pt_comparisons, \"deseq2_adj_time_pt_visualization\")\n",
    "#     print(\"deseq2_compare_w_time_pt_0_visualization:\")\n",
    "#     run_visualization(deseq2_subnetwork_data_2, deseq2_time_pt_0_comparisons, \"deseq2_compare_w_time_pt_0_visualization\")\n",
    "\n",
    "#     print(\"cd_adj_time_pt_visualization:\")\n",
    "#     run_visualization(cd_subnetwork_data_1, cd_adj_time_pt_comparisons, \"cd_adj_time_pt_visualization\")\n",
    "#     print(\"cd_compare_w_time_pt_0_visualization:\")\n",
    "#     run_visualization(cd_subnetwork_data_2, cd_time_pt_0_comparisons, \"cd_compare_w_time_pt_0_visualization\")\n",
    "# else:\n",
    "#     input_json_1 = subnetwork_data_1\n",
    "#     run_visualization(input_json_1, comparisons_1, \"deseq2_adj_time_pt_visualization\")\n",
    "\n",
    "#     input_json_2 = subnetwork_data_2\n",
    "#     run_visualization(input_json_2, comparisons_2, \"deseq2_compare_w_time_pt_0_visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e94259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_degs:\n",
    "    print(\"deseq2_adj_time_pt_visualization:\")\n",
    "    run_visualization(deseq2_subnetwork_data_1, deseq2_adj_time_pt_comparisons, \"deseq2_adj_time_pt_visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_degs:\n",
    "    print(\"deseq2_compare_w_time_pt_0_visualization:\")\n",
    "    run_visualization(deseq2_subnetwork_data_2, deseq2_time_pt_0_comparisons, \"deseq2_compare_w_time_pt_0_visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_degs:\n",
    "    print(\"cd_adj_time_pt_visualization:\")\n",
    "    run_visualization(cd_subnetwork_data_1, cd_adj_time_pt_comparisons, \"cd_adj_time_pt_visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375df57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_degs:\n",
    "    print(\"cd_compare_w_time_pt_0_visualization:\")\n",
    "    run_visualization(cd_subnetwork_data_2, cd_time_pt_0_comparisons, \"cd_compare_w_time_pt_0_visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64243b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not compute_degs:\n",
    "    input_json_1 = subnetwork_data_1\n",
    "    run_visualization(input_json_1, comparisons_1, \"deseq2_adj_time_pt_visualization\")\n",
    "\n",
    "    input_json_2 = subnetwork_data_2\n",
    "    run_visualization(input_json_2, comparisons_2, \"deseq2_compare_w_time_pt_0_visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c947143",
   "metadata": {},
   "source": [
    "## 5. Generating a UMAP visualization for enriched TFs\n",
    "\n",
    "### The enriched transcription factors from each time point are colored on a UMAP plot of 700 TFs identified by ChEA to be \"source TFs\" (i.e. they exert regulatory effects on other TFs). The UMAP algorithm was performed using the TF-IDF scores of the TFs' target genes, meaning that TFs placed in the same cluster generally regulate similar genes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90965bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_scatterplot(libdict, nneighbors=30, mindist=0.1, spread=1.0, maxdf=1.0, mindf=1):\n",
    "    print(\"\\tTF-IDF vectorizing gene set data...\")\n",
    "    vec = TfidfVectorizer(max_df=maxdf, min_df=mindf)\n",
    "    X = vec.fit_transform(libdict.values())\n",
    "    print(X.shape)\n",
    "    adata = anndata.AnnData(X)\n",
    "    adata.obs.index = libdict.keys()\n",
    "\n",
    "    print(\"\\tPerforming Leiden clustering...\")\n",
    "    ### the nneighbors and min_dist parameters can be altered\n",
    "    sc.pp.neighbors(adata, n_neighbors=nneighbors)\n",
    "    sc.tl.leiden(adata, resolution=1.0)\n",
    "    sc.tl.umap(adata, min_dist=mindist, spread=spread, random_state=42)\n",
    "\n",
    "    new_order = adata.obs.sort_values(by='leiden').index.tolist()\n",
    "    adata = adata[new_order, :]\n",
    "    adata.obs['leiden'] = 'Cluster ' + adata.obs['leiden'].astype('object')\n",
    "\n",
    "    df = pd.DataFrame(adata.obsm['X_umap'])\n",
    "    df.columns = ['x', 'y']\n",
    "\n",
    "    df['cluster'] = adata.obs['leiden'].values\n",
    "    df['term'] = adata.obs.index\n",
    "    df['genes'] = [libdict[l] for l in df['term']]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_scatter_colors(df):\n",
    "    clusters = pd.unique(df['cluster']).tolist()\n",
    "    n_clusters = len(clusters)\n",
    "    gray_shades = [f'#{int(v):02x}{int(v):02x}{int(v):02x}' for v in np.linspace(50, 230, n_clusters)]\n",
    "    color_mapper = {clusters[i]: gray_shades[i] for i in range(n_clusters)}\n",
    "    return color_mapper\n",
    "\n",
    "\n",
    "def generate_df_for_comparison(base_df, tf_pair, comparison_label, comparison_idx):\n",
    "    \"\"\"\n",
    "    Generates a new df for each time point.\n",
    "    \"\"\"\n",
    "    up_tfs, down_tfs = tf_pair[0], tf_pair[1]\n",
    "    df = base_df.copy()\n",
    "    color_mapper = get_scatter_colors(df)\n",
    "    df['color'] = df['cluster'].apply(lambda x: color_mapper[x])\n",
    "    df['size'] = 6\n",
    "    df['time_point'] = \"Not enriched\"\n",
    "\n",
    "    for idx, term in df['term'].items():\n",
    "        if (term in up_tfs) and (term not in down_tfs):\n",
    "            df.at[idx, 'color'] = \"#1595f0\"\n",
    "            df.at[idx, 'size'] = 12\n",
    "            df.at[idx, 'time_point'] = comparison_label\n",
    "        if (term in down_tfs) and (term not in up_tfs):\n",
    "            df.at[idx, 'color'] = \"#f30a1a\"\n",
    "            df.at[idx, 'size'] = 12\n",
    "            df.at[idx, 'time_point'] = comparison_label\n",
    "        if (term in up_tfs) and (term in down_tfs):\n",
    "            df.at[idx, 'color'] = \"#26e411\"\n",
    "            df.at[idx, 'size'] = 12\n",
    "            df.at[idx, 'time_point'] = comparison_label\n",
    "    return df\n",
    "\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io.export import export_png\n",
    "from bokeh.models import ColumnDataSource, HoverTool, Slider, CustomJS, Title, Label\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import Greys\n",
    "from bokeh.io import show\n",
    "from bokeh.plotting import output_file, save\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_scatterplot(scatterdf, tf_time_dict=None, comparisons=None, legend_description=None, image_dir=None, gif_filename=None):\n",
    "    \"\"\"\n",
    "    Generates images navigable via a slider, as well as all the images separately.\n",
    "    \"\"\"\n",
    "    df = scatterdf.copy()\n",
    "    df['cluster_number'] = df['cluster'].apply(lambda x: int(x.split(\" \")[-1]))\n",
    "    print(df['cluster_number'])\n",
    "    df.sort_values(by=['cluster_number'], inplace=True)\n",
    "    df.drop(columns = ['cluster_number'], inplace=True)\n",
    "\n",
    "    sources = []\n",
    "    for i, label in enumerate(comparisons):\n",
    "        df_comp = generate_df_for_comparison(df, tf_time_dict[i], label, i)\n",
    "        source = ColumnDataSource(data=dict(x = df_comp['x'], y = df_comp['y'],\n",
    "                                            gene_set = df_comp['term'], colors = df_comp['color'],\n",
    "                                            label = df_comp['cluster'], size = df_comp['size'],\n",
    "                                            time_point = df_comp['time_point']))\n",
    "        sources.append(source)\n",
    "\n",
    "    source = sources[0]\n",
    "    tooltips = [\n",
    "        (\"Gene Set\", \"@gene_set\"),\n",
    "        (\"Cluster\", \"@label\"),\n",
    "        (\"Time point\", \"@time_point\")\n",
    "    ]\n",
    "\n",
    "    hover_emb = HoverTool(tooltips=tooltips)\n",
    "    tools_emb = [hover_emb, 'pan', 'wheel_zoom', 'reset', 'save']\n",
    "\n",
    "    plot_emb = figure(\n",
    "        width=500*2,\n",
    "        height=400*2,\n",
    "        tools=tools_emb,\n",
    "        output_backend='canvas'\n",
    "    )\n",
    "\n",
    "    plot_emb.scatter(\n",
    "        'x',\n",
    "        'y',\n",
    "        size = 'size',\n",
    "        source = source,\n",
    "        marker='circle',\n",
    "        fill_color = 'colors',\n",
    "        color='colors',\n",
    "        legend_group = 'label',\n",
    "    )\n",
    "\n",
    "    # hide axis labels and grid lines\n",
    "    plot_title = Title(text=comparisons[0], align='center')\n",
    "    plot_title.text_font_size = '20pt'\n",
    "    plot_title.text_font_style = 'bold'\n",
    "    plot_emb.add_layout(plot_title, 'above')\n",
    "\n",
    "    plot_emb.xaxis.major_tick_line_color = None\n",
    "    plot_emb.xaxis.minor_tick_line_color = None\n",
    "    plot_emb.yaxis.major_tick_line_color = None\n",
    "    plot_emb.yaxis.minor_tick_line_color = None\n",
    "    plot_emb.grid.grid_line_color = None\n",
    "    plot_emb.xaxis.major_label_text_font_size = '0pt'\n",
    "    plot_emb.yaxis.major_label_text_font_size = '0pt'\n",
    "\n",
    "    plot_emb.xaxis.axis_label = \"UMAP-1\"\n",
    "    plot_emb.yaxis.axis_label = \"UMAP-2\"\n",
    "    plot_emb.xaxis.axis_label_text_font_size = '20pt'\n",
    "    plot_emb.yaxis.axis_label_text_font_size = '20pt'\n",
    "    plot_emb.xaxis.axis_label_text_font_style = \"normal\"\n",
    "    plot_emb.yaxis.axis_label_text_font_style = \"normal\"\n",
    "\n",
    "    plot_emb.legend.label_text_font_size = '18pt'\n",
    "    plot_emb.legend.glyph_height = 20\n",
    "    plot_emb.legend.glyph_width = 20\n",
    "\n",
    "    print(\"legend\", plot_emb.legend[0])\n",
    "    plot_emb.add_layout(plot_emb.legend[0], 'right')\n",
    "\n",
    "    plot_emb.min_border_bottom = 168\n",
    "\n",
    "    description_label = Label(x=0, y=-7, x_units='screen', y_units='screen',\n",
    "                          text=legend_description,\n",
    "                          text_font_size='12pt', text_align='left')\n",
    "\n",
    "    plot_emb.add_layout(description_label, 'below')\n",
    "\n",
    "    ### adding a slider ###\n",
    "    slider = Slider(start=0, end=len(sources) - 1, value=0, step=1, title=\"Comparison\")\n",
    "    comparison_source = ColumnDataSource(data=dict(comparisons=[str(c) for c in comparisons]))\n",
    "    callback = CustomJS(args=dict(source=source, slider=slider, sources=sources, plot=plot_emb,\n",
    "                                  comparison_source=comparison_source, title_obj=plot_title), code=\"\"\"\n",
    "        const i = slider.value;\n",
    "        const new_data = sources[i].data;\n",
    "        const copied_data = {};\n",
    "        for (const key in new_data) {\n",
    "            copied_data[key] = [...new_data[key]];  // deep copy each column\n",
    "        }\n",
    "        source.data = copied_data;\n",
    "\n",
    "        const comp_labels = comparison_source.data['comparisons'];\n",
    "        title_obj.text = comp_labels[i];\n",
    "\n",
    "        source.change.emit();\n",
    "    \"\"\")\n",
    "    slider.js_on_change('value', callback)\n",
    "    show(column(slider, plot_emb))\n",
    "\n",
    "    ### can either show or save the plot (cannot do both)\n",
    "    # output_file(\"top_10_tfs_deseq2_adjacent_time_pts_umap_plot.html\")\n",
    "    # save(column(slider, plot_emb))\n",
    "\n",
    "    ### for isolated individual time point images ###\n",
    "    frame_dir = os.path.join(os.getcwd(), image_dir)\n",
    "    os.makedirs(frame_dir, exist_ok=True)\n",
    "    for i, label in enumerate(comparisons):\n",
    "        source.data = dict(sources[i].data)\n",
    "        plot_title.text = label\n",
    "        export_png(plot_emb, filename=os.path.join(frame_dir, f\"frame_{i:02d}_{label}.png\"))\n",
    "\n",
    "    frame_paths = sorted([os.path.join(frame_dir, f) for f in os.listdir(frame_dir) if f.endswith(\".png\")])\n",
    "    images = [Image.open(frame) for frame in frame_paths]\n",
    "    images[0].save(gif_filename, save_all=True, append_images=images[1:], duration=1500, loop=0)\n",
    "    # display(IPyImage(filename=gif_filename))\n",
    "    display(FileLink(gif_filename, result_html_prefix=\"Click here to download: \"))\n",
    "    print(\"CREATED GIF\")\n",
    "\n",
    "    return plot_emb, source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://minio.dev.maayanlab.cloud/hgrn-chear/network_target_sets.gmt\")\n",
    "file = r.text.split(\"\\n\")\n",
    "\n",
    "lib_dict = OrderedDict()\n",
    "for line in file[:-1]:\n",
    "    tokens = line.split(\"\\t\\t\")\n",
    "    term = tokens[0]\n",
    "    genes = [x.split(',')[0].strip() for x in tokens[1].split('\\t')]\n",
    "    lib_dict[term] = ' '.join(genes)\n",
    "\n",
    "## defaults: nneighbors=30, mindist=0.1, spread=1.0, maxdf=1.0, mindf=1\n",
    "scatter_df = process_scatterplot(\n",
    "    lib_dict,\n",
    "    nneighbors=20,\n",
    "    mindist=0.15,\n",
    ")\n",
    "\n",
    "legend_description = (\"Blue dots are TFs enriched for upregulated DEGs.\\n\"\n",
    "    \"Red dots are TFs enriched for downregulated DEGs.\\n\"\n",
    "    \"Green dots are TFs enriched for both up- and downregulated DEGs.\\n\")\n",
    "legend_description += umap_desc\n",
    "\n",
    "if compute_degs:\n",
    "    deseq2_plot_emb_1, deseq2_source_1 = get_scatterplot(scatter_df, deseq2_tf_time_dict_1, deseq2_adj_time_pt_comparisons, legend_description, \"umap_png_frames_deseq2_adjacent_time_pts_top_5_tfs\", \"top_5_tfs_deseq2_adjacent_time_pts_umap.gif\")\n",
    "    deseq2_plot_emb_2, deseq2_source_2 = get_scatterplot(scatter_df, deseq2_tf_time_dict_2, deseq2_time_pt_0_comparisons, legend_description, \"umap_png_frames_deseq2_compare_w_time_pt_0_top_5_tfs\", \"top_5_tfs_deseq2_compare_w_time_pt_0_umap.gif\")\n",
    "\n",
    "    cd_plot_emb_1, cd_source_1 = get_scatterplot(scatter_df, cd_tf_time_dict_1, cd_adj_time_pt_comparisons, legend_description, \"umap_png_frames_cd_adjacent_time_pts_top_5_tfs\", \"top_5_tfs_cd_adjacent_time_pts_umap.gif\")\n",
    "    cd_plot_emb_2, cd_source_2 = get_scatterplot(scatter_df, cd_tf_time_dict_2, cd_time_pt_0_comparisons, legend_description, \"umap_png_frames_cd_compare_w_time_pt_0_top_5_tfs\", \"top_5_tfs_cd_compare_w_time_pt_0_umap.gif\")\n",
    "else:\n",
    "    plot_emb_1, source_1 = get_scatterplot(scatter_df, tf_time_dict_1, comparisons_1, legend_description, \"umap_png_frames_deseq2_adjacent_time_pts_top_5_tfs\", \"top_5_tfs_deseq2_adjacent_time_pts_umap.gif\")\n",
    "    plot_emb_2, source_2 = get_scatterplot(scatter_df, tf_time_dict_2, comparisons_2, legend_description, \"umap_png_frames_deseq2_compare_w_time_pt_0_top_5_tfs\", \"top_5_tfs_deseq2_compare_w_time_pt_0_umap.gif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appyter_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

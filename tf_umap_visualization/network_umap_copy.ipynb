{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andrewjenkinsvandusen/Downloads/mount_sinai_internship/new_umap_env/bin/python\n",
      "4.33.0\n",
      "2.2.0\n",
      "/Users/andrewjenkinsvandusen/Downloads/mount_sinai_internship/new_umap_env/lib/python3.11/site-packages/numpy/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import selenium\n",
    "print(selenium.__version__)\n",
    "\n",
    "import numpy\n",
    "print(numpy.__version__)\n",
    "print(numpy.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"a9715e0d-ef1a-4da6-bdd6-7301d8c05e41\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"a9715e0d-ef1a-4da6-bdd6-7301d8c05e41\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.7.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"a9715e0d-ef1a-4da6-bdd6-7301d8c05e41\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import chromedriver_binary\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "from collections import OrderedDict\n",
    "from bokeh.io import output_notebook, export_png, export_svg\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import HoverTool, ColumnDataSource\n",
    "from bokeh.palettes import Category20\n",
    "import glasbey\n",
    "output_notebook()\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network(networkdir):\n",
    "    up = pd.read_csv(f\"{networkdir}/Transcription Factor.upregulates.Transcription Factor.edges.csv\", usecols=[\"source_label\",\"target_label\"])\n",
    "    down = pd.read_csv(f\"{networkdir}/Transcription Factor.downregulates.Transcription Factor.edges.csv\",usecols=[\"source_label\",\"target_label\"])\n",
    "    nodes = pd.read_csv(f\"{networkdir}/Transcription Factor.nodes.csv\",usecols=[\"label\"])\n",
    "    return up,down,nodes\n",
    "\n",
    "def find_neighbors(edge_list):\n",
    "    neighbors = defaultdict(list)\n",
    "    for (source, target) in edge_list:\n",
    "        neighbors[source].append(target)\n",
    "    return neighbors\n",
    "\n",
    "up,down,nodes = load_network(\"/Users/andrewjenkinsvandusen/Downloads/mount_sinai_internship/tf_umap_visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Convert the network to a GMT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_dir = \"/Users/andrewjenkinsvandusen/Downloads/mount_sinai_internship/tf_umap_visualization\"\n",
    "up = pd.read_csv(f\"{network_dir}/Transcription Factor.upregulates.Transcription Factor.edges.csv\", usecols=[\"source_label\",\"target_label\"])\n",
    "down = pd.read_csv(f\"{network_dir}/Transcription Factor.downregulates.Transcription Factor.edges.csv\",usecols=[\"source_label\",\"target_label\"])\n",
    "edges = pd.concat([up, down], ignore_index=True)\n",
    "\n",
    "edgelist = list(zip(edges[\"source_label\"], edges[\"target_label\"])) # generates list of tuples\n",
    "gmt = {}\n",
    "for (source, target) in edgelist:\n",
    "    if source in gmt.keys():\n",
    "        gmt[source].append(target)\n",
    "    else:\n",
    "        gmt[source] = [target]\n",
    "\n",
    "with open(\"./network_gmt.gmt\", \"w\") as file:\n",
    "    for s,t in gmt.items():\n",
    "        file.write(str(s) + \"\\t\\t\" + \"\\t\".join(t) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Build the UMAP using code from the Enrichr processing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "libname = 'network_gmt'\n",
    "libdir = '/Users/andrewjenkinsvandusen/Downloads/mount_sinai_internship/tf_umap_visualization' # directory where library is\n",
    "\n",
    "def get_scatter_library(libname, local, augmented):\n",
    "    '''\n",
    "    Processes the GMT file for the input Enrichr library {lib} and returns a\n",
    "    dictionary where the keys correspond to gene set names, and the value for\n",
    "    each key is a space-delimited string containing all genes belonging to\n",
    "    the gene set:\n",
    "    {\n",
    "        \"gene set name\": \"gene_1 gene_2 gene_3 ... gene_n\",\n",
    "        ...\n",
    "    }\n",
    "    In addition, this function can augment each gene set library using ARCHS4\n",
    "    gene-gene co-expression data. For each gene set, the most co-expressed genes\n",
    "    (determined by summing the coexpression coefficients across all genes)\n",
    "    are added to the gene set before visualization.\n",
    "    '''\n",
    "    ### open local file or from Enrichr\n",
    "    if local:\n",
    "        print(f\"\\tOpening library locally from '{libdir}'...\")\n",
    "        with open(f\"{libdir}/{libname}.gmt\", 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "    ### variables to store gene set data\n",
    "    lib_dict = OrderedDict()\n",
    "\n",
    "    if augmented:\n",
    "        print(\"\\tProcessing gene sets and augmenting with ARCHS4...\")\n",
    "    else:\n",
    "        print(\"\\tProcessing gene sets without augmentation...\")\n",
    "\n",
    "    for line in lines:\n",
    "        tokens = line.split(\"\\t\\t\")\n",
    "        term = tokens[0]\n",
    "        genes = [x.split(',')[0].strip() for x in tokens[1].split('\\t')]\n",
    "        lib_dict[term] = ' '.join(genes)\n",
    "\n",
    "    return lib_dict\n",
    "\n",
    "def process_scatterplot(libdict, nneighbors=30, mindist=0.1, spread=1.0, maxdf=1.0, mindf=1):\n",
    "    print(\"\\tTF-IDF vectorizing gene set data...\")\n",
    "    vec = TfidfVectorizer(max_df=maxdf, min_df=mindf)\n",
    "    X = vec.fit_transform(libdict.values())\n",
    "    print(X.shape)\n",
    "    adata = anndata.AnnData(X)\n",
    "    adata.obs.index = libdict.keys()\n",
    "\n",
    "    print(\"\\tPerforming Leiden clustering...\")\n",
    "    ### the nneighbors and min_dist parameters can be altered\n",
    "    sc.pp.neighbors(adata, n_neighbors=nneighbors)\n",
    "    sc.tl.leiden(adata, resolution=1.0)\n",
    "    sc.tl.umap(adata, min_dist=mindist, spread=spread, random_state=42)\n",
    "\n",
    "    new_order = adata.obs.sort_values(by='leiden').index.tolist()\n",
    "    adata = adata[new_order, :]\n",
    "    adata.obs['leiden'] = 'Cluster ' + adata.obs['leiden'].astype('object')\n",
    "\n",
    "    df = pd.DataFrame(adata.obsm['X_umap'])\n",
    "    df.columns = ['x', 'y']\n",
    "\n",
    "    df['cluster'] = adata.obs['leiden'].values\n",
    "    df['term'] = adata.obs.index\n",
    "    df['genes'] = [libdict[l] for l in df['term']]\n",
    "\n",
    "    return df\n",
    "\n",
    "# def get_scatter_colors(df):\n",
    "#     clusters = pd.unique(df['cluster']).tolist()\n",
    "#     colors = glasbey.create_palette(palette_size=len(clusters), lightness_bounds=(0,100), chroma_bounds=(50,100), as_hex=True)\n",
    "#     color_mapper = {clusters[i]: colors[i % 20] for i in range(len(clusters))}\n",
    "#     return color_mapper\n",
    "\n",
    "# def get_scatter_colors(df):\n",
    "#     clusters = pd.unique(df['cluster']).tolist()\n",
    "#     gray = '#808080'  # standard medium gray\n",
    "#     color_mapper = {cluster: gray for cluster in clusters}\n",
    "#     return color_mapper\n",
    "\n",
    "def get_scatter_colors(df):\n",
    "    clusters = pd.unique(df['cluster']).tolist()\n",
    "    n_clusters = len(clusters)\n",
    "    gray_shades = [f'#{int(v):02x}{int(v):02x}{int(v):02x}' for v in np.linspace(50, 230, n_clusters)]\n",
    "    color_mapper = {clusters[i]: gray_shades[i] for i in range(n_clusters)}\n",
    "    return color_mapper\n",
    "\n",
    "def blend_colors(color_hex, factor):\n",
    "    \"\"\"\n",
    "    Outputs a slightly modified hex color given a hex color input.\n",
    "    \"\"\"\n",
    "    rgb = mcolors.to_rgb(color_hex)\n",
    "    adjusted = tuple(min(1, c * factor) for c in rgb)\n",
    "    return mcolors.to_hex(adjusted)\n",
    "\n",
    "def generate_df_for_comparison(base_df, tf_pair, comparison_label, comparison_idx):\n",
    "    \"\"\"\n",
    "    Generates a new df for each time point.\n",
    "    \"\"\"\n",
    "    up_tfs, down_tfs = tf_pair[0], tf_pair[1]\n",
    "    df = base_df.copy()\n",
    "    color_mapper = get_scatter_colors(df)\n",
    "    df['color'] = df['cluster'].apply(lambda x: color_mapper[x])\n",
    "    df['size'] = 6\n",
    "    df['time_point'] = \"Not enriched\"\n",
    "\n",
    "    for idx, term in df['term'].items():\n",
    "        if (term in up_tfs) and (term not in down_tfs):\n",
    "            # df.at[idx, 'color'] = blend_colors('#1f77b4', 1 + 0.2 * comparison_idx)\n",
    "            df.at[idx, 'color'] = \"#1595f0\"\n",
    "            df.at[idx, 'size'] = 12\n",
    "            df.at[idx, 'time_point'] = comparison_label\n",
    "        if (term in down_tfs) and (term not in up_tfs):\n",
    "            # df.at[idx, 'color'] = blend_colors('#b41f29', 1 + 0.2 * comparison_idx)\n",
    "            df.at[idx, 'color'] = \"#f30a1a\"\n",
    "            df.at[idx, 'size'] = 12\n",
    "            df.at[idx, 'time_point'] = comparison_label\n",
    "        if (term in up_tfs) and (term in down_tfs):\n",
    "            df.at[idx, 'color'] = \"#26e411\"\n",
    "            df.at[idx, 'size'] = 12\n",
    "            df.at[idx, 'time_point'] = comparison_label\n",
    "    return df\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io.export import export_png\n",
    "from bokeh.models import ColumnDataSource, HoverTool, Slider, CustomJS, Title, Label\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import Greys\n",
    "from bokeh.io import show\n",
    "from bokeh.plotting import output_file, save\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def get_scatterplot(scatterdf, tf_time_dict=None, comparisons=None, legend_description=None):\n",
    "    \"\"\"\n",
    "    Generates images navigable via a slider, as well as all the images separately.\n",
    "    \"\"\"\n",
    "    df = scatterdf.copy()\n",
    "    df['cluster_number'] = df['cluster'].apply(lambda x: int(x.split(\" \")[-1]))\n",
    "    print(df['cluster_number'])\n",
    "    df.sort_values(by=['cluster_number'], inplace=True)\n",
    "    df.drop(columns = ['cluster_number'], inplace=True)\n",
    "\n",
    "    sources = []\n",
    "    for i, label in enumerate(comparisons):\n",
    "        df_comp = generate_df_for_comparison(df, tf_time_dict[i], label, i)\n",
    "        source = ColumnDataSource(data=dict(x = df_comp['x'], y = df_comp['y'],\n",
    "                                            gene_set = df_comp['term'], colors = df_comp['color'],\n",
    "                                            label = df_comp['cluster'], size = df_comp['size'],\n",
    "                                            time_point = df_comp['time_point']))\n",
    "        sources.append(source)\n",
    "\n",
    "    source = sources[0]\n",
    "    tooltips = [\n",
    "        (\"Gene Set\", \"@gene_set\"),\n",
    "        (\"Cluster\", \"@label\"),\n",
    "        (\"Time point\", \"@time_point\")\n",
    "    ]\n",
    "\n",
    "    hover_emb = HoverTool(tooltips=tooltips)\n",
    "    tools_emb = [hover_emb, 'pan', 'wheel_zoom', 'reset', 'save']\n",
    "\n",
    "    plot_emb = figure(\n",
    "        width=500*2,\n",
    "        height=400*2,\n",
    "        tools=tools_emb,\n",
    "        output_backend='canvas'\n",
    "    )\n",
    "\n",
    "    plot_emb.scatter(\n",
    "        'x',\n",
    "        'y',\n",
    "        size = 'size',\n",
    "        source = source,\n",
    "        marker='circle',\n",
    "        fill_color = 'colors',\n",
    "        color='colors',\n",
    "        legend_group = 'label',\n",
    "    )\n",
    "\n",
    "    # hide axis labels and grid lines\n",
    "    plot_title = Title(text=comparisons[0], align='center')\n",
    "    plot_title.text_font_size = '20pt'\n",
    "    plot_title.text_font_style = 'bold'\n",
    "    plot_emb.add_layout(plot_title, 'above')\n",
    "\n",
    "    plot_emb.xaxis.major_tick_line_color = None\n",
    "    plot_emb.xaxis.minor_tick_line_color = None\n",
    "    plot_emb.yaxis.major_tick_line_color = None\n",
    "    plot_emb.yaxis.minor_tick_line_color = None\n",
    "    plot_emb.grid.grid_line_color = None\n",
    "    plot_emb.xaxis.major_label_text_font_size = '0pt'\n",
    "    plot_emb.yaxis.major_label_text_font_size = '0pt'\n",
    "\n",
    "    plot_emb.xaxis.axis_label = \"UMAP-1\"\n",
    "    plot_emb.yaxis.axis_label = \"UMAP-2\"\n",
    "    plot_emb.xaxis.axis_label_text_font_size = '20pt'\n",
    "    plot_emb.yaxis.axis_label_text_font_size = '20pt'\n",
    "    plot_emb.xaxis.axis_label_text_font_style = \"normal\"\n",
    "    plot_emb.yaxis.axis_label_text_font_style = \"normal\"\n",
    "\n",
    "    plot_emb.legend.label_text_font_size = '18pt'\n",
    "    plot_emb.legend.glyph_height = 20\n",
    "    plot_emb.legend.glyph_width = 20\n",
    "\n",
    "    print(\"legend\", plot_emb.legend[0])\n",
    "    plot_emb.add_layout(plot_emb.legend[0], 'right')\n",
    "\n",
    "    plot_emb.min_border_bottom = 168\n",
    "\n",
    "    description_label = Label(x=0, y=-7, x_units='screen', y_units='screen',\n",
    "                          text=legend_description,\n",
    "                          text_font_size='12pt', text_align='left')\n",
    "\n",
    "    plot_emb.add_layout(description_label, 'below')\n",
    "\n",
    "    ### adding a slider ###\n",
    "    slider = Slider(start=0, end=len(sources) - 1, value=0, step=1, title=\"Comparison\")\n",
    "    comparison_source = ColumnDataSource(data=dict(comparisons=[str(c) for c in comparisons]))\n",
    "    callback = CustomJS(args=dict(source=source, slider=slider, sources=sources, plot=plot_emb,\n",
    "                                  comparison_source=comparison_source, title_obj=plot_title), code=\"\"\"\n",
    "        const i = slider.value;\n",
    "        const new_data = sources[i].data;\n",
    "        const copied_data = {};\n",
    "        for (const key in new_data) {\n",
    "            copied_data[key] = [...new_data[key]];  // deep copy each column\n",
    "        }\n",
    "        source.data = copied_data;\n",
    "\n",
    "        const comp_labels = comparison_source.data['comparisons'];\n",
    "        title_obj.text = comp_labels[i];\n",
    "\n",
    "        source.change.emit();\n",
    "    \"\"\")\n",
    "    slider.js_on_change('value', callback)\n",
    "    # show(column(slider, plot_emb))\n",
    "\n",
    "    # output_file(\"top_10_tfs_deseq2_adjacent_time_pts_umap_plot.html\")\n",
    "    output_file(\"top_10_tfs_deseq2_compare_w_time_pt_0_umap_plot.html\")\n",
    "    save(column(slider, plot_emb))\n",
    "\n",
    "    ### for isolated individual time point images ###\n",
    "    # frame_dir = \"umap_png_frames_deseq2_adjacent_time_pts_top_10_tfs\"\n",
    "    frame_dir = \"umap_png_frames_deseq2_compare_w_time_pt_0_top_10_tfs\"\n",
    "    os.makedirs(frame_dir, exist_ok=True)\n",
    "    for i, label in enumerate(comparisons):\n",
    "        source.data = dict(sources[i].data)\n",
    "        plot_title.text = label\n",
    "        export_png(plot_emb, filename=os.path.join(frame_dir, f\"frame_{i:02d}_{label}.png\"))\n",
    "\n",
    "    return plot_emb, source\n",
    "\n",
    "def create_umap_gif(frame_dir, gif_filename, duration):\n",
    "    \"\"\"\n",
    "    Creates GIF given individual input images found in frame_dir.\n",
    "    \"\"\"\n",
    "    frame_paths = sorted([os.path.join(frame_dir, f) for f in os.listdir(frame_dir) if f.endswith(\".png\")])\n",
    "    images = [Image.open(frame) for frame in frame_paths]\n",
    "    images[0].save(gif_filename, save_all=True, append_images=images[1:], duration=duration, loop=0)\n",
    "    return \"CREATED GIF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tOpening library locally from '/Users/andrewjenkinsvandusen/Downloads/mount_sinai_internship/tf_umap_visualization'...\n",
      "\tProcessing gene sets without augmentation...\n",
      "Now processing network_gmt\n",
      "\tTF-IDF vectorizing gene set data...\n",
      "(700, 1550)\n",
      "\tPerforming Leiden clustering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewjenkinsvandusen/Downloads/mount_sinai_internship/new_umap_env/lib/python3.11/site-packages/scanpy/neighbors/__init__.py:586: UserWarning: Youâ€™re trying to run this on 1550 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n",
      "         Falling back to preprocessing with `sc.pp.pca` and default params.\n",
      "  X = _choose_representation(self._adata, use_rep=use_rep, n_pcs=n_pcs)\n",
      "/var/folders/hs/y48w23_j2gbcvl8vwwd1p3dc0000gn/T/ipykernel_55376/46447333.py:57: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['leiden'] = 'Cluster ' + adata.obs['leiden'].astype('object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDone!\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "695    15\n",
      "696    15\n",
      "697    15\n",
      "698    15\n",
      "699    15\n",
      "Name: cluster_number, Length: 700, dtype: int64\n",
      "legend Legend(id='p3945', ...)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CREATED GIF'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(5, 35, 5):\n",
    "#     for j in [k * 0.05 for k in range(1, 11)]:\n",
    "\n",
    "l_dict = get_scatter_library(libname, local=True, augmented=False)\n",
    "print(f\"Now processing {libname}\") # print(f\"Now processing {libname} with nneighbors = {i} and mindist = {j}\")\n",
    "## defaults: nneighbors=30, mindist=0.1, spread=1.0, maxdf=1.0, mindf=1\n",
    "scatter_df = process_scatterplot(\n",
    "    l_dict,\n",
    "    nneighbors=20,\n",
    "    mindist=0.15,\n",
    ")\n",
    "print(f\"\\tDone!\")\n",
    "\n",
    "# Display Scatter Plots\n",
    "caption1 = f\"**Figure 1. Scatterplot of all terms in the {libname} gene set library.** Each point represents a term in the library. \\\n",
    "    Term frequency-inverse document frequency (TF-IDF) values were computed for the gene set corresponding to each term, and UMAP was  \\\n",
    "    applied to the resulting values. The terms are plotted based on the first two UMAP dimensions. Generally, terms with more similar \\\n",
    "    gene sets are positioned closer together. Terms are colored by automatically identified clusters computed with the Leiden algorithm \\\n",
    "    applied to the TF-IDF values. Hovering over points will display the term and the automatically assigned cluster.\"\n",
    "\n",
    "# deseq2, comparing adjacent time pts\n",
    "# tf_time_dict_1 = {0: (['ATF3', 'KLF6', 'FOSB', 'JUN', 'SNAI1', 'NFIL3', 'FOS', 'NR4A3', 'FOSL1', 'EGR2'], ['NR4A1', 'BHLHE40', 'ZNF395', 'ATF3', 'FOSB', 'ZNF740', 'JUN', 'ZNF594', 'PRDM8', 'ZNF324']), 1: (['BHLHE40', 'ATF3', 'MYC', 'JUNB', 'FOSB', 'FOSL2', 'NFKB1', 'SNAI1', 'RELB', 'FOSL1'], ['BHLHE40', 'ATF3', 'CREBL2', 'KLF7', 'ZBED3', 'FOXA1', 'JUN', 'ZNF608', 'PPARG', 'NR2F2']), 2: (['HMGA2', 'TEAD1', 'SP3', 'PRDM4', 'ZBED4', 'TCF20', 'ZBTB38', 'FOXM1', 'UBP1', 'GLYR1'], ['MAFF', 'HMGN3', 'ATF3', 'FOSB', 'ZNF581', 'EGR1', 'JUN', 'GTF3A', 'ZNF207', 'ZNF511']), 3: (['STAT2', 'CREB3', 'JUN', 'SP100', 'BATF2', 'PPARG', 'TRAFD1', 'IRF1', 'IRF9', 'STAT3'], ['GATAD2A', 'E2F1', 'MYC', 'FOXK2', 'ZBED4', 'ZNF598', 'TCF3', 'SRCAP', 'FOXM1', 'FOSL1']), 4: (['TEAD1', 'STAT2', 'HIF1A', 'NFKB2', 'CREB3L2', 'NFKB1', 'STAT1', 'MAFK', 'ZNF697', 'STAT3'], ['MYC', 'ZNF239', 'ZNF146', 'TFDP1', 'PRMT3', 'CEBPG', 'ETV4', 'FOSL1', 'HMGA1', 'CEBPZ'])}\n",
    "\n",
    "# deseq2, comparing to time pt 0\n",
    "tf_time_dict_2 = {0: (['ATF3', 'KLF6', 'FOSB', 'JUN', 'SNAI1', 'NFIL3', 'FOS', 'NR4A3', 'FOSL1', 'EGR2'], ['NR4A1', 'BHLHE40', 'ZNF395', 'ATF3', 'FOSB', 'ZNF740', 'JUN', 'ZNF594', 'PRDM8', 'ZNF324']), 1: (['ATF3', 'MYC', 'JUNB', 'FOSB', 'FOSL2', 'JUN', 'SNAI1', 'NFIL3', 'NR4A3', 'FOSL1'], ['TEAD1', 'BHLHE40', 'CREBL2', 'ZNF436', 'TFCP2L1', 'TCF7L2', 'CREB3L2', 'JUN', 'KLF9', 'SOX13']), 2: (['ADNP2', 'PRDM4', 'FOXK2', 'ZBED4', 'HIVEP1', 'TCF20', 'BAZ2A', 'ZNF697', 'SRCAP', 'FOSL1'], ['CREB3', 'ELF3', 'CREB3L4', 'JUN', 'ZNF580', 'PPARG', 'NR1H3', 'KLF2', 'IRF9', 'ZNF524']), 3: (['HMGA2', 'ZNF267', 'HIVEP1', 'ZBTB11', 'NFKB2', 'MGA', 'ZNF134', 'NFKB1', 'RLF', 'RELB'], ['E2F1', 'E2F7', 'MBD3', 'THAP4', 'THAP7', 'ZNF837', 'ZNF580', 'TFDP1', 'ZNF511', 'HMGA1']), 4: (['TEAD1', 'ZNF407', 'HIVEP1', 'MGA', 'TCF20', 'SMAD3', 'RFX7', 'ASH1L', 'NFAT5', 'NCOA2'], ['E2F1', 'DRAP1', 'THAP4', 'THAP7', 'MYC', 'ZNF598', 'ZNF692', 'GTF3A', 'TFDP1', 'HMGA1'])}\n",
    "\n",
    "# comparisons_1 = [\"Hour 1 vs Hour 0\", \"Hour 3 vs Hour 1\", \"Hour 6 vs Hour 3\", \"Hour 12 vs Hour 6\", \"Hour 24 vs Hour 12\"]\n",
    "comparisons_2 = [\"Hour 1 vs Hour 0\", \"Hour 3 vs Hour 0\", \"Hour 6 vs Hour 0\", \"Hour 12 vs Hour 0\", \"Hour 24 vs Hour 0\"]\n",
    "\n",
    "legend_description = (\"Blue dots are TFs enriched for upregulated DEGs.\\n\"\n",
    "    \"Red dots are TFs enriched for downregulated DEGs.\\n\"\n",
    "    \"Green dots are TFs enriched for both up- and downregulated DEGs.\\n\"\n",
    "    \"This study looked at the response of a triple-negative breast cancer cell line to TRAIL.\\n\"\n",
    "    \"RNA-seq samples were taken at six time points (0, 1, 3, 6, 12, & 24 hours).\")\n",
    "\n",
    "# plot, source = get_scatterplot(scatter_df, tf_time_dict_1, comparisons_1, legend_description)\n",
    "plot, source = get_scatterplot(scatter_df, tf_time_dict_2, comparisons_2, legend_description)\n",
    "# print(plot)\n",
    "# display(HTML(f\"<div style='font-size:1.5rem;'>Scatter plot visualization for {libname}.</div>\"))\n",
    "# show(plot)\n",
    "\n",
    "# create_umap_gif(\"umap_png_frames_deseq2_adjacent_time_pts_top_10_tfs\", \"top_10_tfs_deseq2_adjacent_time_pts_umap.gif\", 1500)\n",
    "create_umap_gif(\"umap_png_frames_deseq2_compare_w_time_pt_0_top_10_tfs\", \"top_10_tfs_deseq2_compare_w_time_pt_0_umap.gif\", 1500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_umap_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
